//g++ ANN.cpp `pkg-config --libs opencv`
#include <opencv2/opencv.hpp>
#include <opencv2/highgui/highgui.hpp>
#include<dirent.h>
#include<string.h>
#include<iostream>
#include<stdio.h>
#define nh 6
#define ni 960
#define no 4
#define epochs 150
using namespace std;
using namespace cv;
double input[1000][ni+1];
double output[1000][no];
double hiddenN[nh+1];   // Hidden Layer Results
double outputN[no];  //  Output Layer Results
double deltah[ni+1][nh]; //delta  First set of weights 
double deltao[nh+1][no]; // delta Second set of weights
double wh[ni+1][nh]; // First set of weights 
double wo[nh+1][no]; // Second set of weights
double grado[no]; // gradient for output layer
double gradh[nh+1]; // gradient for hidden layer
double alpha =0.3; // Learning Rate
double momentum=0.3; //momentum
int current; // Current Input

void init(){ // Initialize weights
  srand(time(NULL));
  int i,j;
  for(i=0;i<=ni;i++) for(j=0;j<nh;j++) wh[i][j] =((float)rand() / (double)RAND_MAX) * 0.2 - 0.1; 
  for(i=0;i<=nh;i++) for(j=0;j<no;j++) wo[i][j] =((float)rand() / (double)RAND_MAX) * 0.2 - 0.1;
}


/*void initializeWeights()
{	srand(time(NULL));
	//set range
	double rH = 1/sqrt( (double) ni);
	double rO = 1/sqrt( (double) nh);
	//double rH = 4*sqrt( 6/((double) ni+no+1));
	//double rO = 4*sqrt( 6/((double) nh+2));
	
	//set weights between input and hidden 		
	//--------------------------------------------------------------------------------------------------------
	for(int i = 0; i <= ni; i++)
	{		
		for(int j = 0; j < nh; j++) 
		{
			//set weights to random values
			wh[i][j] = ( ( (double)(rand()%100)+1)/100  * 2 * rH ) - rH;
			wh[i][j]*=30;			
		}
	}
	
	//set weights between input and hidden
	//--------------------------------------------------------------------------------------------------------
	for(int i = 0; i <= nh; i++)
	{		
		for(int j = 0; j < no; j++) 
		{
			//set weights to random values
			wo[i][j] = ( ( (double)(rand()%100)+1)/100 * 2 * rO ) - rO;
			wo[i][j]*=30;
		}
	}
}*/

double sigmoid(double x){ //Sigmoid Function
 return (double)1/((double)1+exp(double(-x)));
}

void ffeed(){

	for(int j=0; j < nh; j++)
	{
		//clear value
		hiddenN[j] = 0;				
		
		//get weighted sum of pattern and bias neuron
		for( int i=0; i <= ni; i++ ) hiddenN[j] += input[current][i]*wh[i][j];
		
		//set to result of sigmoid
		hiddenN[j] = sigmoid( hiddenN[j] );			
	}
	
	//Calculating Output Layer values - include bias neuron
	//--------------------------------------------------------------------------------------------------------
	for(int k=0; k < no; k++)
	{
		//clear value
		outputN[k] = 0;				
		
		//get weighted sum of pattern and bias neuron
		for( int j=0; j <= nh; j++ ) outputN[k] += hiddenN[j]*wo[j][k];
		
		//set to result of sigmoid
		outputN[k] = sigmoid( outputN[k] );
	}


}

void updateW(){
	//input -> hidden weights
	//--------------------------------------------------------------------------------------------------------
	for (int i = 0; i <= ni; i++)
	{
		for (int j = 0; j < nh; j++) 
		{
			//update weight
			wh[i][j] += deltah[i][j];	
			
		}
	}
	
	//hidden -> output weights
	//--------------------------------------------------------------------------------------------------------
	for (int j = 0; j <= nh; j++)
	{
		for (int k = 0; k < no; k++) 
		{					
			//update weight
			wo[j][k] += deltao[j][k];
		}
	}					

}

void backprop()
{		
	//modify deltas between hidden and output layers
	//--------------------------------------------------------------------------------------------------------
	for (int k = 0; k < no; k++)
	{
		//get error gradient for every output node
		grado[k] = outputN[k]*(1-outputN[k])*(output[current][k]-outputN[k]);
		
		//for all nodes in hidden layer and bias neuron
		for (int j = 0; j <= nh; j++) 
		{				
			//calculate change in weight
			deltao[j][k] = alpha*hiddenN[j]*grado[k] + momentum*deltao[j][k];

		}
	}

	//modify deltas between input and hidden layers
	//--------------------------------------------------------------------------------------------------------
	for (int j = 0; j < nh; j++)
	{
		//get error gradient for every hidden node
		double weightedSum = 0;
		for( int k = 0; k < no; k++ ) weightedSum += wo[j][k] * grado[k];
		gradh[j] = hiddenN[j]*(1-hiddenN[j])*weightedSum;

		//for all nodes in input layer and bias neuron
		for (int i = 0; i <= ni; i++)
		{
			//calculate change in weight 
			deltah[i][j] = alpha*input[current][i]*gradh[j] + momentum*deltah[i][j];

		}
	}
	updateW();
	
}


int main(){
 hiddenN[nh]=-1; //bias
 int c=0;
 DIR *dir;
 char *pch;
 string dirName ="/home/mypc/ML/assignment2/faces_4/an2i";
 char pre[100] = "faces_4/an2i/";
 dir = opendir(dirName.c_str());
 struct dirent *ent;
 FILE *trainingSet = fopen("all_train.list","r");
 char filename[100];
 while(fgets(trainingSet,
 
 /*while((ent=readdir(dir))!=NULL){
	char pre[100] = "faces_4/an2i/";
	if(strlen(ent->d_name)<20) continue;
	Mat m=imread(strcat(pre,ent->d_name));
	uint8_t *data = m.data;
        //if(m.rows*m.cols!=ni){ printf("ERROR"); return 0;}
	for(int i=0;i<m.rows;i++){
		input[c][0]=1;
		for(int j=0;j<m.cols;j++) input[c][i*m.cols+j] = (double)data[i*m.cols+j]/255;
	}
	input[c][ni]=-1; //bias
	pch = strtok(ent->d_name,"_");
	pch = strtok(NULL,"_");
	//pch = strtok(NULL,"_");
	//pch = strtok(NULL,"_");
	if(strcmp(pch,"left")==0) output[c][0]=1;	
	else if(strcmp(pch,"right")==0) output[c][1]=1;
	else if(strcmp(pch,"straight")==0) output[c][2]=1;	
	else if(strcmp(pch,"up")==0) output[c][3]=1;
	c+=1;
 	//break;
 }	
 init(); //intialize weghts
 int d=0;
 for(int i=0;i<epochs;i++){   //Train the weights
  double temp=0;
  for(current=0;current<c;current++){
   ffeed();
   backprop(); 
   for(int x=0;x<no;x++) temp+=pow(outputN[x]-output[current][x],2);
  }
  printf("%lf  %d\n",temp,i);
 }
 for(current=0;current<c;current++){
 ffeed();
 int i;
 for(i=0;i<no;i++) if((double)(outputN[i]>0.5)!=output[current][i]) break;
 if(i==no) d+=1;
 }
 printf("training accuracy %lf",d*100.0/c);
 printf("\n%d",c);*/

 return 0;
}












